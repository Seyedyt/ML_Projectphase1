{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b106033a",
      "metadata": {
        "id": "b106033a"
      },
      "source": [
        "## Data Preparation\n",
        "We'll start by importing the necessary libraries and preparing the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cbdeb275",
      "metadata": {
        "id": "cbdeb275"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e8c626ba",
      "metadata": {
        "id": "e8c626ba"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Transformations for the CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "74e9ef58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74e9ef58",
        "outputId": "f3488227-c2f0-46c0-ae54-bcc1049a1ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Original training dataset size: 50000\n"
          ]
        }
      ],
      "source": [
        "# Download CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "print(f'Original training dataset size: {len(train_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8GQ34G6wbynK",
      "metadata": {
        "id": "8GQ34G6wbynK"
      },
      "outputs": [],
      "source": [
        "# Function to split dataset into shards and slices\n",
        "def split_dataset(dataset, num_shards, num_slices):\n",
        "    shard_size = len(dataset) // num_shards\n",
        "    shards = [Subset(dataset, range(i * shard_size, (i + 1) * shard_size)) for i in range(num_shards)]\n",
        "    slices = []\n",
        "    for shard in shards:\n",
        "        slice_size = len(shard) // num_slices\n",
        "        shard_slices = [Subset(shard, range(j * slice_size, (j + 1) * slice_size)) for j in range(num_slices)]\n",
        "        slices.append(shard_slices)\n",
        "    return slices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mVhQgfAOMtT0",
      "metadata": {
        "id": "mVhQgfAOMtT0"
      },
      "source": [
        "## Model Training\n",
        "Next, we'll define a function to train the model using the slices from each shard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Ty3tLS41My-Z",
      "metadata": {
        "id": "Ty3tLS41My-Z"
      },
      "outputs": [],
      "source": [
        "def train_model_on_slices(slices, epochs_per_slice):\n",
        "    trained_models = []\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    print('Training...')\n",
        "\n",
        "    print(f'Number of shards (slices): {len(slices)}')\n",
        "    counter1 = 0  # Counter for shards\n",
        "    counter2 = 0  # Counter for slices\n",
        "\n",
        "    for shard in slices:\n",
        "        counter1 += 1\n",
        "        print(f'Training shard {counter1}/{len(slices)}')\n",
        "\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        # Modify ResNet-18 to add fully connected layers\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)  # CIFAR-10 has 10 classes\n",
        "        )\n",
        "        model = model.to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        print(f'Number of slices in shard {counter1}: {len(shard)}')\n",
        "        for slice in shard:\n",
        "            counter2 += 1\n",
        "            print(f'Training slice {counter2} in shard {counter1}')\n",
        "\n",
        "            dataloader = DataLoader(slice, batch_size=64, shuffle=True)\n",
        "            model.train()\n",
        "            for epoch in range(epochs_per_slice):\n",
        "                for images, labels in dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "        trained_models.append(model)\n",
        "\n",
        "    return trained_models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6muK7Hm9M3k0",
      "metadata": {
        "id": "6muK7Hm9M3k0"
      },
      "source": [
        "## Model Aggregation\n",
        "We'll aggregate the trained models by averaging their predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ia8kAYBHM5ns",
      "metadata": {
        "id": "ia8kAYBHM5ns"
      },
      "outputs": [],
      "source": [
        "def aggregate_models(trained_models, dataloader):\n",
        "    all_probabilities = []\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    loop_count = 0  # Counter for the number of iterations\n",
        "    dataloader_size = len(dataloader)\n",
        "    print(f'DataLoader size (number of batches): {dataloader_size}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            print(f'Iteration: {loop_count}')\n",
        "            loop_count += 1  # Increment counter\n",
        "            images = images.to(device)\n",
        "            outputs = [model(images).cpu() for model in trained_models]\n",
        "            avg_output = sum(outputs) / len(outputs)\n",
        "            probabilities = nn.Softmax(dim=1)(avg_output)  # Apply softmax to get probabilities\n",
        "            _, predictions = torch.max(probabilities, 1)\n",
        "            all_probabilities.extend(probabilities.numpy())\n",
        "            all_predictions.extend(predictions.numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    print(f'The for loop in aggregate_models ran {loop_count} times.')\n",
        "    return all_probabilities, all_predictions, all_labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E3Si7mGANA9L",
      "metadata": {
        "id": "E3Si7mGANA9L"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(probabilities, predictions, labels):\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    precision = precision_score(labels, predictions, average='macro')\n",
        "    recall = recall_score(labels, predictions, average='macro')\n",
        "    # For AUROC, we need probabilities\n",
        "    auroc = roc_auc_score(labels, probabilities, multi_class='ovr')\n",
        "    return f1, accuracy, precision, recall, auroc\n",
        "\n"
      ],
      "metadata": {
        "id": "wl-HoJukeOu_"
      },
      "id": "wl-HoJukeOu_",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the results and models\n",
        "initial_results = []\n",
        "trained_models_dict = {}"
      ],
      "metadata": {
        "id": "3uSIuJFEpO2O"
      },
      "id": "3uSIuJFEpO2O",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "_wQZMV4YM9kd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wQZMV4YM9kd",
        "collapsed": true,
        "outputId": "e43786cd-2a78-45d1-ef8c-d7ede4041f42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with S=20, R=20...\n",
            "Training...\n",
            "Number of shards (slices): 20\n",
            "Training shard 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 88.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slices in shard 1: 20\n",
            "Training slice 1 in shard 1\n",
            "Training slice 2 in shard 1\n",
            "Training slice 3 in shard 1\n",
            "Training slice 4 in shard 1\n",
            "Training slice 5 in shard 1\n",
            "Training slice 6 in shard 1\n",
            "Training slice 7 in shard 1\n",
            "Training slice 8 in shard 1\n",
            "Training slice 9 in shard 1\n",
            "Training slice 10 in shard 1\n",
            "Training slice 11 in shard 1\n",
            "Training slice 12 in shard 1\n",
            "Training slice 13 in shard 1\n",
            "Training slice 14 in shard 1\n",
            "Training slice 15 in shard 1\n",
            "Training slice 16 in shard 1\n",
            "Training slice 17 in shard 1\n",
            "Training slice 18 in shard 1\n",
            "Training slice 19 in shard 1\n",
            "Training slice 20 in shard 1\n",
            "Training shard 2/20\n",
            "Number of slices in shard 2: 20\n",
            "Training slice 21 in shard 2\n",
            "Training slice 22 in shard 2\n",
            "Training slice 23 in shard 2\n",
            "Training slice 24 in shard 2\n",
            "Training slice 25 in shard 2\n",
            "Training slice 26 in shard 2\n",
            "Training slice 27 in shard 2\n",
            "Training slice 28 in shard 2\n",
            "Training slice 29 in shard 2\n",
            "Training slice 30 in shard 2\n",
            "Training slice 31 in shard 2\n",
            "Training slice 32 in shard 2\n",
            "Training slice 33 in shard 2\n",
            "Training slice 34 in shard 2\n",
            "Training slice 35 in shard 2\n",
            "Training slice 36 in shard 2\n",
            "Training slice 37 in shard 2\n",
            "Training slice 38 in shard 2\n",
            "Training slice 39 in shard 2\n",
            "Training slice 40 in shard 2\n",
            "Training shard 3/20\n",
            "Number of slices in shard 3: 20\n",
            "Training slice 41 in shard 3\n",
            "Training slice 42 in shard 3\n",
            "Training slice 43 in shard 3\n",
            "Training slice 44 in shard 3\n",
            "Training slice 45 in shard 3\n",
            "Training slice 46 in shard 3\n",
            "Training slice 47 in shard 3\n",
            "Training slice 48 in shard 3\n",
            "Training slice 49 in shard 3\n",
            "Training slice 50 in shard 3\n",
            "Training slice 51 in shard 3\n",
            "Training slice 52 in shard 3\n",
            "Training slice 53 in shard 3\n",
            "Training slice 54 in shard 3\n",
            "Training slice 55 in shard 3\n",
            "Training slice 56 in shard 3\n",
            "Training slice 57 in shard 3\n",
            "Training slice 58 in shard 3\n",
            "Training slice 59 in shard 3\n",
            "Training slice 60 in shard 3\n",
            "Training shard 4/20\n",
            "Number of slices in shard 4: 20\n",
            "Training slice 61 in shard 4\n",
            "Training slice 62 in shard 4\n",
            "Training slice 63 in shard 4\n",
            "Training slice 64 in shard 4\n",
            "Training slice 65 in shard 4\n",
            "Training slice 66 in shard 4\n",
            "Training slice 67 in shard 4\n",
            "Training slice 68 in shard 4\n",
            "Training slice 69 in shard 4\n",
            "Training slice 70 in shard 4\n",
            "Training slice 71 in shard 4\n",
            "Training slice 72 in shard 4\n",
            "Training slice 73 in shard 4\n",
            "Training slice 74 in shard 4\n",
            "Training slice 75 in shard 4\n",
            "Training slice 76 in shard 4\n",
            "Training slice 77 in shard 4\n",
            "Training slice 78 in shard 4\n",
            "Training slice 79 in shard 4\n",
            "Training slice 80 in shard 4\n",
            "Training shard 5/20\n",
            "Number of slices in shard 5: 20\n",
            "Training slice 81 in shard 5\n",
            "Training slice 82 in shard 5\n",
            "Training slice 83 in shard 5\n",
            "Training slice 84 in shard 5\n",
            "Training slice 85 in shard 5\n",
            "Training slice 86 in shard 5\n",
            "Training slice 87 in shard 5\n",
            "Training slice 88 in shard 5\n",
            "Training slice 89 in shard 5\n",
            "Training slice 90 in shard 5\n",
            "Training slice 91 in shard 5\n",
            "Training slice 92 in shard 5\n",
            "Training slice 93 in shard 5\n",
            "Training slice 94 in shard 5\n",
            "Training slice 95 in shard 5\n",
            "Training slice 96 in shard 5\n",
            "Training slice 97 in shard 5\n",
            "Training slice 98 in shard 5\n",
            "Training slice 99 in shard 5\n",
            "Training slice 100 in shard 5\n",
            "Training shard 6/20\n",
            "Number of slices in shard 6: 20\n",
            "Training slice 101 in shard 6\n",
            "Training slice 102 in shard 6\n",
            "Training slice 103 in shard 6\n",
            "Training slice 104 in shard 6\n",
            "Training slice 105 in shard 6\n",
            "Training slice 106 in shard 6\n",
            "Training slice 107 in shard 6\n",
            "Training slice 108 in shard 6\n",
            "Training slice 109 in shard 6\n",
            "Training slice 110 in shard 6\n",
            "Training slice 111 in shard 6\n",
            "Training slice 112 in shard 6\n",
            "Training slice 113 in shard 6\n",
            "Training slice 114 in shard 6\n",
            "Training slice 115 in shard 6\n",
            "Training slice 116 in shard 6\n",
            "Training slice 117 in shard 6\n",
            "Training slice 118 in shard 6\n",
            "Training slice 119 in shard 6\n",
            "Training slice 120 in shard 6\n",
            "Training shard 7/20\n",
            "Number of slices in shard 7: 20\n",
            "Training slice 121 in shard 7\n",
            "Training slice 122 in shard 7\n",
            "Training slice 123 in shard 7\n",
            "Training slice 124 in shard 7\n",
            "Training slice 125 in shard 7\n",
            "Training slice 126 in shard 7\n",
            "Training slice 127 in shard 7\n",
            "Training slice 128 in shard 7\n",
            "Training slice 129 in shard 7\n",
            "Training slice 130 in shard 7\n",
            "Training slice 131 in shard 7\n",
            "Training slice 132 in shard 7\n",
            "Training slice 133 in shard 7\n",
            "Training slice 134 in shard 7\n",
            "Training slice 135 in shard 7\n",
            "Training slice 136 in shard 7\n",
            "Training slice 137 in shard 7\n",
            "Training slice 138 in shard 7\n",
            "Training slice 139 in shard 7\n",
            "Training slice 140 in shard 7\n",
            "Training shard 8/20\n",
            "Number of slices in shard 8: 20\n",
            "Training slice 141 in shard 8\n",
            "Training slice 142 in shard 8\n",
            "Training slice 143 in shard 8\n",
            "Training slice 144 in shard 8\n",
            "Training slice 145 in shard 8\n",
            "Training slice 146 in shard 8\n",
            "Training slice 147 in shard 8\n",
            "Training slice 148 in shard 8\n",
            "Training slice 149 in shard 8\n",
            "Training slice 150 in shard 8\n",
            "Training slice 151 in shard 8\n",
            "Training slice 152 in shard 8\n",
            "Training slice 153 in shard 8\n",
            "Training slice 154 in shard 8\n",
            "Training slice 155 in shard 8\n",
            "Training slice 156 in shard 8\n",
            "Training slice 157 in shard 8\n",
            "Training slice 158 in shard 8\n",
            "Training slice 159 in shard 8\n",
            "Training slice 160 in shard 8\n",
            "Training shard 9/20\n",
            "Number of slices in shard 9: 20\n",
            "Training slice 161 in shard 9\n",
            "Training slice 162 in shard 9\n",
            "Training slice 163 in shard 9\n",
            "Training slice 164 in shard 9\n",
            "Training slice 165 in shard 9\n",
            "Training slice 166 in shard 9\n",
            "Training slice 167 in shard 9\n",
            "Training slice 168 in shard 9\n",
            "Training slice 169 in shard 9\n",
            "Training slice 170 in shard 9\n",
            "Training slice 171 in shard 9\n",
            "Training slice 172 in shard 9\n",
            "Training slice 173 in shard 9\n",
            "Training slice 174 in shard 9\n",
            "Training slice 175 in shard 9\n",
            "Training slice 176 in shard 9\n",
            "Training slice 177 in shard 9\n",
            "Training slice 178 in shard 9\n",
            "Training slice 179 in shard 9\n",
            "Training slice 180 in shard 9\n",
            "Training shard 10/20\n",
            "Number of slices in shard 10: 20\n",
            "Training slice 181 in shard 10\n",
            "Training slice 182 in shard 10\n",
            "Training slice 183 in shard 10\n",
            "Training slice 184 in shard 10\n",
            "Training slice 185 in shard 10\n",
            "Training slice 186 in shard 10\n",
            "Training slice 187 in shard 10\n",
            "Training slice 188 in shard 10\n",
            "Training slice 189 in shard 10\n",
            "Training slice 190 in shard 10\n",
            "Training slice 191 in shard 10\n",
            "Training slice 192 in shard 10\n",
            "Training slice 193 in shard 10\n",
            "Training slice 194 in shard 10\n",
            "Training slice 195 in shard 10\n",
            "Training slice 196 in shard 10\n",
            "Training slice 197 in shard 10\n",
            "Training slice 198 in shard 10\n",
            "Training slice 199 in shard 10\n",
            "Training slice 200 in shard 10\n",
            "Training shard 11/20\n",
            "Number of slices in shard 11: 20\n",
            "Training slice 201 in shard 11\n",
            "Training slice 202 in shard 11\n",
            "Training slice 203 in shard 11\n",
            "Training slice 204 in shard 11\n",
            "Training slice 205 in shard 11\n",
            "Training slice 206 in shard 11\n",
            "Training slice 207 in shard 11\n",
            "Training slice 208 in shard 11\n",
            "Training slice 209 in shard 11\n",
            "Training slice 210 in shard 11\n",
            "Training slice 211 in shard 11\n",
            "Training slice 212 in shard 11\n",
            "Training slice 213 in shard 11\n",
            "Training slice 214 in shard 11\n",
            "Training slice 215 in shard 11\n",
            "Training slice 216 in shard 11\n",
            "Training slice 217 in shard 11\n",
            "Training slice 218 in shard 11\n",
            "Training slice 219 in shard 11\n",
            "Training slice 220 in shard 11\n",
            "Training shard 12/20\n",
            "Number of slices in shard 12: 20\n",
            "Training slice 221 in shard 12\n",
            "Training slice 222 in shard 12\n",
            "Training slice 223 in shard 12\n",
            "Training slice 224 in shard 12\n",
            "Training slice 225 in shard 12\n",
            "Training slice 226 in shard 12\n",
            "Training slice 227 in shard 12\n",
            "Training slice 228 in shard 12\n",
            "Training slice 229 in shard 12\n",
            "Training slice 230 in shard 12\n",
            "Training slice 231 in shard 12\n",
            "Training slice 232 in shard 12\n",
            "Training slice 233 in shard 12\n",
            "Training slice 234 in shard 12\n",
            "Training slice 235 in shard 12\n",
            "Training slice 236 in shard 12\n",
            "Training slice 237 in shard 12\n",
            "Training slice 238 in shard 12\n",
            "Training slice 239 in shard 12\n",
            "Training slice 240 in shard 12\n",
            "Training shard 13/20\n",
            "Number of slices in shard 13: 20\n",
            "Training slice 241 in shard 13\n",
            "Training slice 242 in shard 13\n",
            "Training slice 243 in shard 13\n",
            "Training slice 244 in shard 13\n",
            "Training slice 245 in shard 13\n",
            "Training slice 246 in shard 13\n",
            "Training slice 247 in shard 13\n",
            "Training slice 248 in shard 13\n",
            "Training slice 249 in shard 13\n",
            "Training slice 250 in shard 13\n",
            "Training slice 251 in shard 13\n",
            "Training slice 252 in shard 13\n",
            "Training slice 253 in shard 13\n",
            "Training slice 254 in shard 13\n",
            "Training slice 255 in shard 13\n",
            "Training slice 256 in shard 13\n",
            "Training slice 257 in shard 13\n",
            "Training slice 258 in shard 13\n",
            "Training slice 259 in shard 13\n",
            "Training slice 260 in shard 13\n",
            "Training shard 14/20\n",
            "Number of slices in shard 14: 20\n",
            "Training slice 261 in shard 14\n",
            "Training slice 262 in shard 14\n",
            "Training slice 263 in shard 14\n",
            "Training slice 264 in shard 14\n",
            "Training slice 265 in shard 14\n",
            "Training slice 266 in shard 14\n",
            "Training slice 267 in shard 14\n",
            "Training slice 268 in shard 14\n",
            "Training slice 269 in shard 14\n",
            "Training slice 270 in shard 14\n",
            "Training slice 271 in shard 14\n",
            "Training slice 272 in shard 14\n",
            "Training slice 273 in shard 14\n",
            "Training slice 274 in shard 14\n",
            "Training slice 275 in shard 14\n",
            "Training slice 276 in shard 14\n",
            "Training slice 277 in shard 14\n",
            "Training slice 278 in shard 14\n",
            "Training slice 279 in shard 14\n",
            "Training slice 280 in shard 14\n",
            "Training shard 15/20\n",
            "Number of slices in shard 15: 20\n",
            "Training slice 281 in shard 15\n",
            "Training slice 282 in shard 15\n",
            "Training slice 283 in shard 15\n",
            "Training slice 284 in shard 15\n",
            "Training slice 285 in shard 15\n",
            "Training slice 286 in shard 15\n",
            "Training slice 287 in shard 15\n",
            "Training slice 288 in shard 15\n",
            "Training slice 289 in shard 15\n",
            "Training slice 290 in shard 15\n",
            "Training slice 291 in shard 15\n",
            "Training slice 292 in shard 15\n",
            "Training slice 293 in shard 15\n",
            "Training slice 294 in shard 15\n",
            "Training slice 295 in shard 15\n",
            "Training slice 296 in shard 15\n",
            "Training slice 297 in shard 15\n",
            "Training slice 298 in shard 15\n",
            "Training slice 299 in shard 15\n",
            "Training slice 300 in shard 15\n",
            "Training shard 16/20\n",
            "Number of slices in shard 16: 20\n",
            "Training slice 301 in shard 16\n",
            "Training slice 302 in shard 16\n",
            "Training slice 303 in shard 16\n",
            "Training slice 304 in shard 16\n",
            "Training slice 305 in shard 16\n",
            "Training slice 306 in shard 16\n",
            "Training slice 307 in shard 16\n",
            "Training slice 308 in shard 16\n",
            "Training slice 309 in shard 16\n",
            "Training slice 310 in shard 16\n",
            "Training slice 311 in shard 16\n",
            "Training slice 312 in shard 16\n",
            "Training slice 313 in shard 16\n",
            "Training slice 314 in shard 16\n",
            "Training slice 315 in shard 16\n",
            "Training slice 316 in shard 16\n",
            "Training slice 317 in shard 16\n",
            "Training slice 318 in shard 16\n",
            "Training slice 319 in shard 16\n",
            "Training slice 320 in shard 16\n",
            "Training shard 17/20\n",
            "Number of slices in shard 17: 20\n",
            "Training slice 321 in shard 17\n",
            "Training slice 322 in shard 17\n",
            "Training slice 323 in shard 17\n",
            "Training slice 324 in shard 17\n",
            "Training slice 325 in shard 17\n",
            "Training slice 326 in shard 17\n",
            "Training slice 327 in shard 17\n",
            "Training slice 328 in shard 17\n",
            "Training slice 329 in shard 17\n",
            "Training slice 330 in shard 17\n",
            "Training slice 331 in shard 17\n",
            "Training slice 332 in shard 17\n",
            "Training slice 333 in shard 17\n",
            "Training slice 334 in shard 17\n",
            "Training slice 335 in shard 17\n",
            "Training slice 336 in shard 17\n",
            "Training slice 337 in shard 17\n",
            "Training slice 338 in shard 17\n",
            "Training slice 339 in shard 17\n",
            "Training slice 340 in shard 17\n",
            "Training shard 18/20\n",
            "Number of slices in shard 18: 20\n",
            "Training slice 341 in shard 18\n",
            "Training slice 342 in shard 18\n",
            "Training slice 343 in shard 18\n",
            "Training slice 344 in shard 18\n",
            "Training slice 345 in shard 18\n",
            "Training slice 346 in shard 18\n",
            "Training slice 347 in shard 18\n",
            "Training slice 348 in shard 18\n",
            "Training slice 349 in shard 18\n",
            "Training slice 350 in shard 18\n",
            "Training slice 351 in shard 18\n",
            "Training slice 352 in shard 18\n",
            "Training slice 353 in shard 18\n",
            "Training slice 354 in shard 18\n",
            "Training slice 355 in shard 18\n",
            "Training slice 356 in shard 18\n",
            "Training slice 357 in shard 18\n",
            "Training slice 358 in shard 18\n",
            "Training slice 359 in shard 18\n",
            "Training slice 360 in shard 18\n",
            "Training shard 19/20\n",
            "Number of slices in shard 19: 20\n",
            "Training slice 361 in shard 19\n",
            "Training slice 362 in shard 19\n",
            "Training slice 363 in shard 19\n",
            "Training slice 364 in shard 19\n",
            "Training slice 365 in shard 19\n",
            "Training slice 366 in shard 19\n",
            "Training slice 367 in shard 19\n",
            "Training slice 368 in shard 19\n",
            "Training slice 369 in shard 19\n",
            "Training slice 370 in shard 19\n",
            "Training slice 371 in shard 19\n",
            "Training slice 372 in shard 19\n",
            "Training slice 373 in shard 19\n",
            "Training slice 374 in shard 19\n",
            "Training slice 375 in shard 19\n",
            "Training slice 376 in shard 19\n",
            "Training slice 377 in shard 19\n",
            "Training slice 378 in shard 19\n",
            "Training slice 379 in shard 19\n",
            "Training slice 380 in shard 19\n",
            "Training shard 20/20\n",
            "Number of slices in shard 20: 20\n",
            "Training slice 381 in shard 20\n",
            "Training slice 382 in shard 20\n",
            "Training slice 383 in shard 20\n",
            "Training slice 384 in shard 20\n",
            "Training slice 385 in shard 20\n",
            "Training slice 386 in shard 20\n",
            "Training slice 387 in shard 20\n",
            "Training slice 388 in shard 20\n",
            "Training slice 389 in shard 20\n",
            "Training slice 390 in shard 20\n",
            "Training slice 391 in shard 20\n",
            "Training slice 392 in shard 20\n",
            "Training slice 393 in shard 20\n",
            "Training slice 394 in shard 20\n",
            "Training slice 395 in shard 20\n",
            "Training slice 396 in shard 20\n",
            "Training slice 397 in shard 20\n",
            "Training slice 398 in shard 20\n",
            "Training slice 399 in shard 20\n",
            "Training slice 400 in shard 20\n",
            "DataLoader size (number of batches): 157\n",
            "Iteration: 0\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "The for loop in aggregate_models ran 157 times.\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 20\n",
        "R = 20\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "E3jop7ykM_-y",
      "metadata": {
        "id": "E3jop7ykM_-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "da319d6f-9c4b-4c5c-cdce-32fe714b6d75"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with S=10, R=20...\n",
            "Training...\n",
            "Number of shards (slices): 10\n",
            "Training shard 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slices in shard 1: 20\n",
            "Training slice 1 in shard 1\n",
            "Training slice 2 in shard 1\n",
            "Training slice 3 in shard 1\n",
            "Training slice 4 in shard 1\n",
            "Training slice 5 in shard 1\n",
            "Training slice 6 in shard 1\n",
            "Training slice 7 in shard 1\n",
            "Training slice 8 in shard 1\n",
            "Training slice 9 in shard 1\n",
            "Training slice 10 in shard 1\n",
            "Training slice 11 in shard 1\n",
            "Training slice 12 in shard 1\n",
            "Training slice 13 in shard 1\n",
            "Training slice 14 in shard 1\n",
            "Training slice 15 in shard 1\n",
            "Training slice 16 in shard 1\n",
            "Training slice 17 in shard 1\n",
            "Training slice 18 in shard 1\n",
            "Training slice 19 in shard 1\n",
            "Training slice 20 in shard 1\n",
            "Training shard 2/10\n",
            "Number of slices in shard 2: 20\n",
            "Training slice 21 in shard 2\n",
            "Training slice 22 in shard 2\n",
            "Training slice 23 in shard 2\n",
            "Training slice 24 in shard 2\n",
            "Training slice 25 in shard 2\n",
            "Training slice 26 in shard 2\n",
            "Training slice 27 in shard 2\n",
            "Training slice 28 in shard 2\n",
            "Training slice 29 in shard 2\n",
            "Training slice 30 in shard 2\n",
            "Training slice 31 in shard 2\n",
            "Training slice 32 in shard 2\n",
            "Training slice 33 in shard 2\n",
            "Training slice 34 in shard 2\n",
            "Training slice 35 in shard 2\n",
            "Training slice 36 in shard 2\n",
            "Training slice 37 in shard 2\n",
            "Training slice 38 in shard 2\n",
            "Training slice 39 in shard 2\n",
            "Training slice 40 in shard 2\n",
            "Training shard 3/10\n",
            "Number of slices in shard 3: 20\n",
            "Training slice 41 in shard 3\n",
            "Training slice 42 in shard 3\n",
            "Training slice 43 in shard 3\n",
            "Training slice 44 in shard 3\n",
            "Training slice 45 in shard 3\n",
            "Training slice 46 in shard 3\n",
            "Training slice 47 in shard 3\n",
            "Training slice 48 in shard 3\n",
            "Training slice 49 in shard 3\n",
            "Training slice 50 in shard 3\n",
            "Training slice 51 in shard 3\n",
            "Training slice 52 in shard 3\n",
            "Training slice 53 in shard 3\n",
            "Training slice 54 in shard 3\n",
            "Training slice 55 in shard 3\n",
            "Training slice 56 in shard 3\n",
            "Training slice 57 in shard 3\n",
            "Training slice 58 in shard 3\n",
            "Training slice 59 in shard 3\n",
            "Training slice 60 in shard 3\n",
            "Training shard 4/10\n",
            "Number of slices in shard 4: 20\n",
            "Training slice 61 in shard 4\n",
            "Training slice 62 in shard 4\n",
            "Training slice 63 in shard 4\n",
            "Training slice 64 in shard 4\n",
            "Training slice 65 in shard 4\n",
            "Training slice 66 in shard 4\n",
            "Training slice 67 in shard 4\n",
            "Training slice 68 in shard 4\n",
            "Training slice 69 in shard 4\n",
            "Training slice 70 in shard 4\n",
            "Training slice 71 in shard 4\n",
            "Training slice 72 in shard 4\n",
            "Training slice 73 in shard 4\n",
            "Training slice 74 in shard 4\n",
            "Training slice 75 in shard 4\n",
            "Training slice 76 in shard 4\n",
            "Training slice 77 in shard 4\n",
            "Training slice 78 in shard 4\n",
            "Training slice 79 in shard 4\n",
            "Training slice 80 in shard 4\n",
            "Training shard 5/10\n",
            "Number of slices in shard 5: 20\n",
            "Training slice 81 in shard 5\n",
            "Training slice 82 in shard 5\n",
            "Training slice 83 in shard 5\n",
            "Training slice 84 in shard 5\n",
            "Training slice 85 in shard 5\n",
            "Training slice 86 in shard 5\n",
            "Training slice 87 in shard 5\n",
            "Training slice 88 in shard 5\n",
            "Training slice 89 in shard 5\n",
            "Training slice 90 in shard 5\n",
            "Training slice 91 in shard 5\n",
            "Training slice 92 in shard 5\n",
            "Training slice 93 in shard 5\n",
            "Training slice 94 in shard 5\n",
            "Training slice 95 in shard 5\n",
            "Training slice 96 in shard 5\n",
            "Training slice 97 in shard 5\n",
            "Training slice 98 in shard 5\n",
            "Training slice 99 in shard 5\n",
            "Training slice 100 in shard 5\n",
            "Training shard 6/10\n",
            "Number of slices in shard 6: 20\n",
            "Training slice 101 in shard 6\n",
            "Training slice 102 in shard 6\n",
            "Training slice 103 in shard 6\n",
            "Training slice 104 in shard 6\n",
            "Training slice 105 in shard 6\n",
            "Training slice 106 in shard 6\n",
            "Training slice 107 in shard 6\n",
            "Training slice 108 in shard 6\n",
            "Training slice 109 in shard 6\n",
            "Training slice 110 in shard 6\n",
            "Training slice 111 in shard 6\n",
            "Training slice 112 in shard 6\n",
            "Training slice 113 in shard 6\n",
            "Training slice 114 in shard 6\n",
            "Training slice 115 in shard 6\n",
            "Training slice 116 in shard 6\n",
            "Training slice 117 in shard 6\n",
            "Training slice 118 in shard 6\n",
            "Training slice 119 in shard 6\n",
            "Training slice 120 in shard 6\n",
            "Training shard 7/10\n",
            "Number of slices in shard 7: 20\n",
            "Training slice 121 in shard 7\n",
            "Training slice 122 in shard 7\n",
            "Training slice 123 in shard 7\n",
            "Training slice 124 in shard 7\n",
            "Training slice 125 in shard 7\n",
            "Training slice 126 in shard 7\n",
            "Training slice 127 in shard 7\n",
            "Training slice 128 in shard 7\n",
            "Training slice 129 in shard 7\n",
            "Training slice 130 in shard 7\n",
            "Training slice 131 in shard 7\n",
            "Training slice 132 in shard 7\n",
            "Training slice 133 in shard 7\n",
            "Training slice 134 in shard 7\n",
            "Training slice 135 in shard 7\n",
            "Training slice 136 in shard 7\n",
            "Training slice 137 in shard 7\n",
            "Training slice 138 in shard 7\n",
            "Training slice 139 in shard 7\n",
            "Training slice 140 in shard 7\n",
            "Training shard 8/10\n",
            "Number of slices in shard 8: 20\n",
            "Training slice 141 in shard 8\n",
            "Training slice 142 in shard 8\n",
            "Training slice 143 in shard 8\n",
            "Training slice 144 in shard 8\n",
            "Training slice 145 in shard 8\n",
            "Training slice 146 in shard 8\n",
            "Training slice 147 in shard 8\n",
            "Training slice 148 in shard 8\n",
            "Training slice 149 in shard 8\n",
            "Training slice 150 in shard 8\n",
            "Training slice 151 in shard 8\n",
            "Training slice 152 in shard 8\n",
            "Training slice 153 in shard 8\n",
            "Training slice 154 in shard 8\n",
            "Training slice 155 in shard 8\n",
            "Training slice 156 in shard 8\n",
            "Training slice 157 in shard 8\n",
            "Training slice 158 in shard 8\n",
            "Training slice 159 in shard 8\n",
            "Training slice 160 in shard 8\n",
            "Training shard 9/10\n",
            "Number of slices in shard 9: 20\n",
            "Training slice 161 in shard 9\n",
            "Training slice 162 in shard 9\n",
            "Training slice 163 in shard 9\n",
            "Training slice 164 in shard 9\n",
            "Training slice 165 in shard 9\n",
            "Training slice 166 in shard 9\n",
            "Training slice 167 in shard 9\n",
            "Training slice 168 in shard 9\n",
            "Training slice 169 in shard 9\n",
            "Training slice 170 in shard 9\n",
            "Training slice 171 in shard 9\n",
            "Training slice 172 in shard 9\n",
            "Training slice 173 in shard 9\n",
            "Training slice 174 in shard 9\n",
            "Training slice 175 in shard 9\n",
            "Training slice 176 in shard 9\n",
            "Training slice 177 in shard 9\n",
            "Training slice 178 in shard 9\n",
            "Training slice 179 in shard 9\n",
            "Training slice 180 in shard 9\n",
            "Training shard 10/10\n",
            "Number of slices in shard 10: 20\n",
            "Training slice 181 in shard 10\n",
            "Training slice 182 in shard 10\n",
            "Training slice 183 in shard 10\n",
            "Training slice 184 in shard 10\n",
            "Training slice 185 in shard 10\n",
            "Training slice 186 in shard 10\n",
            "Training slice 187 in shard 10\n",
            "Training slice 188 in shard 10\n",
            "Training slice 189 in shard 10\n",
            "Training slice 190 in shard 10\n",
            "Training slice 191 in shard 10\n",
            "Training slice 192 in shard 10\n",
            "Training slice 193 in shard 10\n",
            "Training slice 194 in shard 10\n",
            "Training slice 195 in shard 10\n",
            "Training slice 196 in shard 10\n",
            "Training slice 197 in shard 10\n",
            "Training slice 198 in shard 10\n",
            "Training slice 199 in shard 10\n",
            "Training slice 200 in shard 10\n",
            "DataLoader size (number of batches): 157\n",
            "Iteration: 0\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "The for loop in aggregate_models ran 157 times.\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 10\n",
        "R = 20\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 5\n",
        "R = 20\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GPQkwsEaGKqc",
        "outputId": "949a4eb4-31e4-41b3-c5e2-d4529559980b"
      },
      "id": "GPQkwsEaGKqc",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with S=5, R=20...\n",
            "Training...\n",
            "Number of shards (slices): 5\n",
            "Training shard 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slices in shard 1: 20\n",
            "Training slice 1 in shard 1\n",
            "Training slice 2 in shard 1\n",
            "Training slice 3 in shard 1\n",
            "Training slice 4 in shard 1\n",
            "Training slice 5 in shard 1\n",
            "Training slice 6 in shard 1\n",
            "Training slice 7 in shard 1\n",
            "Training slice 8 in shard 1\n",
            "Training slice 9 in shard 1\n",
            "Training slice 10 in shard 1\n",
            "Training slice 11 in shard 1\n",
            "Training slice 12 in shard 1\n",
            "Training slice 13 in shard 1\n",
            "Training slice 14 in shard 1\n",
            "Training slice 15 in shard 1\n",
            "Training slice 16 in shard 1\n",
            "Training slice 17 in shard 1\n",
            "Training slice 18 in shard 1\n",
            "Training slice 19 in shard 1\n",
            "Training slice 20 in shard 1\n",
            "Training shard 2/5\n",
            "Number of slices in shard 2: 20\n",
            "Training slice 21 in shard 2\n",
            "Training slice 22 in shard 2\n",
            "Training slice 23 in shard 2\n",
            "Training slice 24 in shard 2\n",
            "Training slice 25 in shard 2\n",
            "Training slice 26 in shard 2\n",
            "Training slice 27 in shard 2\n",
            "Training slice 28 in shard 2\n",
            "Training slice 29 in shard 2\n",
            "Training slice 30 in shard 2\n",
            "Training slice 31 in shard 2\n",
            "Training slice 32 in shard 2\n",
            "Training slice 33 in shard 2\n",
            "Training slice 34 in shard 2\n",
            "Training slice 35 in shard 2\n",
            "Training slice 36 in shard 2\n",
            "Training slice 37 in shard 2\n",
            "Training slice 38 in shard 2\n",
            "Training slice 39 in shard 2\n",
            "Training slice 40 in shard 2\n",
            "Training shard 3/5\n",
            "Number of slices in shard 3: 20\n",
            "Training slice 41 in shard 3\n",
            "Training slice 42 in shard 3\n",
            "Training slice 43 in shard 3\n",
            "Training slice 44 in shard 3\n",
            "Training slice 45 in shard 3\n",
            "Training slice 46 in shard 3\n",
            "Training slice 47 in shard 3\n",
            "Training slice 48 in shard 3\n",
            "Training slice 49 in shard 3\n",
            "Training slice 50 in shard 3\n",
            "Training slice 51 in shard 3\n",
            "Training slice 52 in shard 3\n",
            "Training slice 53 in shard 3\n",
            "Training slice 54 in shard 3\n",
            "Training slice 55 in shard 3\n",
            "Training slice 56 in shard 3\n",
            "Training slice 57 in shard 3\n",
            "Training slice 58 in shard 3\n",
            "Training slice 59 in shard 3\n",
            "Training slice 60 in shard 3\n",
            "Training shard 4/5\n",
            "Number of slices in shard 4: 20\n",
            "Training slice 61 in shard 4\n",
            "Training slice 62 in shard 4\n",
            "Training slice 63 in shard 4\n",
            "Training slice 64 in shard 4\n",
            "Training slice 65 in shard 4\n",
            "Training slice 66 in shard 4\n",
            "Training slice 67 in shard 4\n",
            "Training slice 68 in shard 4\n",
            "Training slice 69 in shard 4\n",
            "Training slice 70 in shard 4\n",
            "Training slice 71 in shard 4\n",
            "Training slice 72 in shard 4\n",
            "Training slice 73 in shard 4\n",
            "Training slice 74 in shard 4\n",
            "Training slice 75 in shard 4\n",
            "Training slice 76 in shard 4\n",
            "Training slice 77 in shard 4\n",
            "Training slice 78 in shard 4\n",
            "Training slice 79 in shard 4\n",
            "Training slice 80 in shard 4\n",
            "Training shard 5/5\n",
            "Number of slices in shard 5: 20\n",
            "Training slice 81 in shard 5\n",
            "Training slice 82 in shard 5\n",
            "Training slice 83 in shard 5\n",
            "Training slice 84 in shard 5\n",
            "Training slice 85 in shard 5\n",
            "Training slice 86 in shard 5\n",
            "Training slice 87 in shard 5\n",
            "Training slice 88 in shard 5\n",
            "Training slice 89 in shard 5\n",
            "Training slice 90 in shard 5\n",
            "Training slice 91 in shard 5\n",
            "Training slice 92 in shard 5\n",
            "Training slice 93 in shard 5\n",
            "Training slice 94 in shard 5\n",
            "Training slice 95 in shard 5\n",
            "Training slice 96 in shard 5\n",
            "Training slice 97 in shard 5\n",
            "Training slice 98 in shard 5\n",
            "Training slice 99 in shard 5\n",
            "Training slice 100 in shard 5\n",
            "DataLoader size (number of batches): 157\n",
            "Iteration: 0\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "The for loop in aggregate_models ran 157 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 20\n",
        "R = 10\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qqqEs2CgGoZP"
      },
      "id": "qqqEs2CgGoZP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 10\n",
        "R = 10\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gUIeqYOtHhtj",
        "outputId": "2ca2c31c-c993-4a2f-b533-5f82bc8e631e"
      },
      "id": "gUIeqYOtHhtj",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with S=10, R=10...\n",
            "Training...\n",
            "Number of shards (slices): 10\n",
            "Training shard 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slices in shard 1: 10\n",
            "Training slice 1 in shard 1\n",
            "Training slice 2 in shard 1\n",
            "Training slice 3 in shard 1\n",
            "Training slice 4 in shard 1\n",
            "Training slice 5 in shard 1\n",
            "Training slice 6 in shard 1\n",
            "Training slice 7 in shard 1\n",
            "Training slice 8 in shard 1\n",
            "Training slice 9 in shard 1\n",
            "Training slice 10 in shard 1\n",
            "Training shard 2/10\n",
            "Number of slices in shard 2: 10\n",
            "Training slice 11 in shard 2\n",
            "Training slice 12 in shard 2\n",
            "Training slice 13 in shard 2\n",
            "Training slice 14 in shard 2\n",
            "Training slice 15 in shard 2\n",
            "Training slice 16 in shard 2\n",
            "Training slice 17 in shard 2\n",
            "Training slice 18 in shard 2\n",
            "Training slice 19 in shard 2\n",
            "Training slice 20 in shard 2\n",
            "Training shard 3/10\n",
            "Number of slices in shard 3: 10\n",
            "Training slice 21 in shard 3\n",
            "Training slice 22 in shard 3\n",
            "Training slice 23 in shard 3\n",
            "Training slice 24 in shard 3\n",
            "Training slice 25 in shard 3\n",
            "Training slice 26 in shard 3\n",
            "Training slice 27 in shard 3\n",
            "Training slice 28 in shard 3\n",
            "Training slice 29 in shard 3\n",
            "Training slice 30 in shard 3\n",
            "Training shard 4/10\n",
            "Number of slices in shard 4: 10\n",
            "Training slice 31 in shard 4\n",
            "Training slice 32 in shard 4\n",
            "Training slice 33 in shard 4\n",
            "Training slice 34 in shard 4\n",
            "Training slice 35 in shard 4\n",
            "Training slice 36 in shard 4\n",
            "Training slice 37 in shard 4\n",
            "Training slice 38 in shard 4\n",
            "Training slice 39 in shard 4\n",
            "Training slice 40 in shard 4\n",
            "Training shard 5/10\n",
            "Number of slices in shard 5: 10\n",
            "Training slice 41 in shard 5\n",
            "Training slice 42 in shard 5\n",
            "Training slice 43 in shard 5\n",
            "Training slice 44 in shard 5\n",
            "Training slice 45 in shard 5\n",
            "Training slice 46 in shard 5\n",
            "Training slice 47 in shard 5\n",
            "Training slice 48 in shard 5\n",
            "Training slice 49 in shard 5\n",
            "Training slice 50 in shard 5\n",
            "Training shard 6/10\n",
            "Number of slices in shard 6: 10\n",
            "Training slice 51 in shard 6\n",
            "Training slice 52 in shard 6\n",
            "Training slice 53 in shard 6\n",
            "Training slice 54 in shard 6\n",
            "Training slice 55 in shard 6\n",
            "Training slice 56 in shard 6\n",
            "Training slice 57 in shard 6\n",
            "Training slice 58 in shard 6\n",
            "Training slice 59 in shard 6\n",
            "Training slice 60 in shard 6\n",
            "Training shard 7/10\n",
            "Number of slices in shard 7: 10\n",
            "Training slice 61 in shard 7\n",
            "Training slice 62 in shard 7\n",
            "Training slice 63 in shard 7\n",
            "Training slice 64 in shard 7\n",
            "Training slice 65 in shard 7\n",
            "Training slice 66 in shard 7\n",
            "Training slice 67 in shard 7\n",
            "Training slice 68 in shard 7\n",
            "Training slice 69 in shard 7\n",
            "Training slice 70 in shard 7\n",
            "Training shard 8/10\n",
            "Number of slices in shard 8: 10\n",
            "Training slice 71 in shard 8\n",
            "Training slice 72 in shard 8\n",
            "Training slice 73 in shard 8\n",
            "Training slice 74 in shard 8\n",
            "Training slice 75 in shard 8\n",
            "Training slice 76 in shard 8\n",
            "Training slice 77 in shard 8\n",
            "Training slice 78 in shard 8\n",
            "Training slice 79 in shard 8\n",
            "Training slice 80 in shard 8\n",
            "Training shard 9/10\n",
            "Number of slices in shard 9: 10\n",
            "Training slice 81 in shard 9\n",
            "Training slice 82 in shard 9\n",
            "Training slice 83 in shard 9\n",
            "Training slice 84 in shard 9\n",
            "Training slice 85 in shard 9\n",
            "Training slice 86 in shard 9\n",
            "Training slice 87 in shard 9\n",
            "Training slice 88 in shard 9\n",
            "Training slice 89 in shard 9\n",
            "Training slice 90 in shard 9\n",
            "Training shard 10/10\n",
            "Number of slices in shard 10: 10\n",
            "Training slice 91 in shard 10\n",
            "Training slice 92 in shard 10\n",
            "Training slice 93 in shard 10\n",
            "Training slice 94 in shard 10\n",
            "Training slice 95 in shard 10\n",
            "Training slice 96 in shard 10\n",
            "Training slice 97 in shard 10\n",
            "Training slice 98 in shard 10\n",
            "Training slice 99 in shard 10\n",
            "Training slice 100 in shard 10\n",
            "DataLoader size (number of batches): 157\n",
            "Iteration: 0\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "The for loop in aggregate_models ran 157 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 5\n",
        "R = 10\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vlVzf06AItaI"
      },
      "id": "vlVzf06AItaI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 20\n",
        "R = 5\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3tFWQIV3Jn3E"
      },
      "id": "3tFWQIV3Jn3E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 10\n",
        "R = 5\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gYJja2ENLaCC",
        "outputId": "77caba5c-8c2d-451a-86b2-c2a8b996d823"
      },
      "id": "gYJja2ENLaCC",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with S=10, R=5...\n",
            "Training...\n",
            "Number of shards (slices): 10\n",
            "Training shard 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of slices in shard 1: 5\n",
            "Training slice 1 in shard 1\n",
            "Training slice 2 in shard 1\n",
            "Training slice 3 in shard 1\n",
            "Training slice 4 in shard 1\n",
            "Training slice 5 in shard 1\n",
            "Training shard 2/10\n",
            "Number of slices in shard 2: 5\n",
            "Training slice 6 in shard 2\n",
            "Training slice 7 in shard 2\n",
            "Training slice 8 in shard 2\n",
            "Training slice 9 in shard 2\n",
            "Training slice 10 in shard 2\n",
            "Training shard 3/10\n",
            "Number of slices in shard 3: 5\n",
            "Training slice 11 in shard 3\n",
            "Training slice 12 in shard 3\n",
            "Training slice 13 in shard 3\n",
            "Training slice 14 in shard 3\n",
            "Training slice 15 in shard 3\n",
            "Training shard 4/10\n",
            "Number of slices in shard 4: 5\n",
            "Training slice 16 in shard 4\n",
            "Training slice 17 in shard 4\n",
            "Training slice 18 in shard 4\n",
            "Training slice 19 in shard 4\n",
            "Training slice 20 in shard 4\n",
            "Training shard 5/10\n",
            "Number of slices in shard 5: 5\n",
            "Training slice 21 in shard 5\n",
            "Training slice 22 in shard 5\n",
            "Training slice 23 in shard 5\n",
            "Training slice 24 in shard 5\n",
            "Training slice 25 in shard 5\n",
            "Training shard 6/10\n",
            "Number of slices in shard 6: 5\n",
            "Training slice 26 in shard 6\n",
            "Training slice 27 in shard 6\n",
            "Training slice 28 in shard 6\n",
            "Training slice 29 in shard 6\n",
            "Training slice 30 in shard 6\n",
            "Training shard 7/10\n",
            "Number of slices in shard 7: 5\n",
            "Training slice 31 in shard 7\n",
            "Training slice 32 in shard 7\n",
            "Training slice 33 in shard 7\n",
            "Training slice 34 in shard 7\n",
            "Training slice 35 in shard 7\n",
            "Training shard 8/10\n",
            "Number of slices in shard 8: 5\n",
            "Training slice 36 in shard 8\n",
            "Training slice 37 in shard 8\n",
            "Training slice 38 in shard 8\n",
            "Training slice 39 in shard 8\n",
            "Training slice 40 in shard 8\n",
            "Training shard 9/10\n",
            "Number of slices in shard 9: 5\n",
            "Training slice 41 in shard 9\n",
            "Training slice 42 in shard 9\n",
            "Training slice 43 in shard 9\n",
            "Training slice 44 in shard 9\n",
            "Training slice 45 in shard 9\n",
            "Training shard 10/10\n",
            "Number of slices in shard 10: 5\n",
            "Training slice 46 in shard 10\n",
            "Training slice 47 in shard 10\n",
            "Training slice 48 in shard 10\n",
            "Training slice 49 in shard 10\n",
            "Training slice 50 in shard 10\n",
            "DataLoader size (number of batches): 157\n",
            "Iteration: 0\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "The for loop in aggregate_models ran 157 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluation process for different configurations\n",
        "S = 5\n",
        "R = 5\n",
        "epochs_per_slice = 1  # Number of epochs to train per slice for quick testing\n",
        "\n",
        "\n",
        "print(f'Training with S={S}, R={R}...')\n",
        "slices = split_dataset(train_dataset, S, R)\n",
        "trained_models = train_model_on_slices(slices, epochs_per_slice)\n",
        "trained_models_dict[(S, R)] = trained_models  # Save the trained models in the dictionary\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate models and evaluate\n",
        "probabilities, predictions, labels = aggregate_models(trained_models, test_loader)\n",
        "metrics = evaluate_model(probabilities, predictions, labels)\n",
        "\n",
        "# Store results\n",
        "initial_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': metrics[0],\n",
        "    'Accuracy': metrics[1],\n",
        "    'Precision': metrics[2],\n",
        "    'Recall': metrics[3],\n",
        "    'AUROC': metrics[4]\n",
        "})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c0zEPtKkMsKf"
      },
      "id": "c0zEPtKkMsKf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "uKCVtGp4XUyV",
      "metadata": {
        "id": "uKCVtGp4XUyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f510ff-daca-48f6-93b2-f585ec270eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration (S=20, R=20):\n",
            "F1 Score: 0.7772965109783782\n",
            "Accuracy: 0.7793\n",
            "Precision: 0.7783406734219726\n",
            "Recall: 0.7792999999999999\n",
            "AUROC: 0.9733346333333334\n",
            "----------------------------\n",
            "Configuration (S=10, R=20):\n",
            "F1 Score: 0.8128525368624011\n",
            "Accuracy: 0.8136\n",
            "Precision: 0.8127508327042022\n",
            "Recall: 0.8135999999999999\n",
            "AUROC: 0.9800214\n",
            "----------------------------\n",
            "Configuration (S=5, R=20):\n",
            "F1 Score: 0.8319313023384268\n",
            "Accuracy: 0.8322\n",
            "Precision: 0.8325433758441733\n",
            "Recall: 0.8321999999999999\n",
            "AUROC: 0.9836772\n",
            "----------------------------\n",
            "Configuration (S=20, R=10):\n",
            "F1 Score: 0.7760504708496643\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.7763365037895612\n",
            "Recall: 0.7777999999999999\n",
            "AUROC: 0.9727531222222222\n",
            "----------------------------\n",
            "Configuration (S=10, R=10):\n",
            "F1 Score: 0.8186887891015788\n",
            "Accuracy: 0.8197\n",
            "Precision: 0.8189822198045075\n",
            "Recall: 0.8197000000000001\n",
            "AUROC: 0.9808543999999999\n",
            "----------------------------\n",
            "Configuration (S=5, R=10):\n",
            "F1 Score: 0.8394757911081394\n",
            "Accuracy: 0.8407\n",
            "Precision: 0.8401477812599282\n",
            "Recall: 0.8407\n",
            "AUROC: 0.9843981111111111\n",
            "----------------------------\n",
            "Configuration (S=20, R=5):\n",
            "F1 Score: 0.7816623576728114\n",
            "Accuracy: 0.7825\n",
            "Precision: 0.7826973988561956\n",
            "Recall: 0.7825\n",
            "AUROC: 0.9740724277777778\n",
            "----------------------------\n",
            "Configuration (S=10, R=5):\n",
            "F1 Score: 0.8210066424025413\n",
            "Accuracy: 0.8209\n",
            "Precision: 0.8219775328562262\n",
            "Recall: 0.8209\n",
            "AUROC: 0.9812070333333333\n",
            "----------------------------\n",
            "Configuration (S=5, R=5):\n",
            "F1 Score: 0.8251634841627162\n",
            "Accuracy: 0.8272\n",
            "Precision: 0.827014751789583\n",
            "Recall: 0.8272\n",
            "AUROC: 0.9832102444444443\n",
            "----------------------------\n"
          ]
        }
      ],
      "source": [
        " # Display results\n",
        "for result in initial_results:\n",
        "    print(f'Configuration (S={result[\"S\"]}, R={result[\"R\"]}):')\n",
        "    print(f'F1 Score: {result[\"F1 Score\"]}')\n",
        "    print(f'Accuracy: {result[\"Accuracy\"]}')\n",
        "    print(f'Precision: {result[\"Precision\"]}')\n",
        "    print(f'Recall: {result[\"Recall\"]}')\n",
        "    print(f'AUROC: {result[\"AUROC\"]}')\n",
        "    print('----------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trained_models_dict)"
      ],
      "metadata": {
        "id": "_dAw7y0N6Unb"
      },
      "id": "_dAw7y0N6Unb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Save the trained models dictionary to a file\n",
        "torch.save(trained_models_dict, 'trained_models_dict.pth')\n",
        "\n",
        "print(\"Trained models dictionary saved to 'trained_models_dict.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRrfPkX16joI",
        "outputId": "b02af992-8506-4f24-c080-5afd174029e9"
      },
      "id": "sRrfPkX16joI",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained models dictionary saved to 'trained_models_dict.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the trained models dictionary from the file\n",
        "trained_models_dict = torch.load('trained_models_dict.pth')\n",
        "\n",
        "print(\"Trained models dictionary loaded from 'trained_models_dict.pth'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0YG8N9CEgT0",
        "outputId": "84c106cf-46d4-422b-f7ad-41103a542c04"
      },
      "id": "o0YG8N9CEgT0",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained models dictionary loaded from 'trained_models_dict.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to unlearn specific data points\n",
        "def unlearn_data(trained_models, data_to_forget, train_dataset, num_shards, num_slices, epochs_per_slice):\n",
        "    # Identify which shards contain the data to be forgotten\n",
        "    shard_indices = np.array_split(range(len(train_dataset)), num_shards)\n",
        "    shards_to_update = set()\n",
        "    for idx in data_to_forget:\n",
        "        for shard_num, shard_idx in enumerate(shard_indices):\n",
        "            if idx in shard_idx:\n",
        "                shards_to_update.add(shard_num)\n",
        "                break\n",
        "\n",
        "    # Retrain only the affected shards\n",
        "    slices = split_dataset(train_dataset, num_shards, num_slices)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for shard_num in shards_to_update:\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)  # CIFAR-10 has 10 classes\n",
        "        )\n",
        "        model = model.to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        # Remove data to be forgotten from the slices\n",
        "        updated_slices = []\n",
        "        for slice in slices[shard_num]:\n",
        "            updated_indices = [idx for idx in slice.indices if idx not in data_to_forget]\n",
        "            updated_slices.append(Subset(train_dataset, updated_indices))\n",
        "\n",
        "        # Retrain the model on the updated slices\n",
        "        for slice in updated_slices:\n",
        "            dataloader = DataLoader(slice, batch_size=64, shuffle=True)\n",
        "            model.train()\n",
        "            for epoch in range(epochs_per_slice):\n",
        "                for images, labels in dataloader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "        trained_models[shard_num] = model  # Update the model for the affected shard\n",
        "\n",
        "    return trained_models\n"
      ],
      "metadata": {
        "id": "VVAteSElGlp_"
      },
      "id": "VVAteSElGlp_",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlearning_results = []"
      ],
      "metadata": {
        "id": "jCkm5FGObIXW"
      },
      "id": "jCkm5FGObIXW",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unlearning phase\n",
        "data_to_forget = np.random.choice(len(train_dataset), 500, replace=False)"
      ],
      "metadata": {
        "id": "0f9PbDEW16ye"
      },
      "id": "0f9PbDEW16ye",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = 20\n",
        "R = 20\n",
        "epochs_per_slice = 1\n",
        "\n",
        "print(f'Unlearning 500 data points for S={S}, R={R}...')\n",
        "trained_models = trained_models_dict[(S, R)]\n",
        "updated_models = unlearn_data(trained_models, data_to_forget, train_dataset, S, R, epochs_per_slice)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Aggregate updated models and evaluate\n",
        "updated_probabilities, updated_predictions, updated_labels = aggregate_models(updated_models, test_loader)\n",
        "updated_metrics = evaluate_model(updated_probabilities, updated_predictions, updated_labels)\n",
        "\n",
        "# Store unlearning results\n",
        "unlearning_results.append({\n",
        "    'S': S,\n",
        "    'R': R,\n",
        "    'F1 Score': updated_metrics[0],\n",
        "    'Accuracy': updated_metrics[1],\n",
        "    'Precision': updated_metrics[2],\n",
        "    'Recall': updated_metrics[3],\n",
        "    'AUROC': updated_metrics[4]\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ccgq5yr4b8wX",
        "outputId": "c3f71258-dd3d-4097-b9b2-0b0cfa007e39"
      },
      "id": "Ccgq5yr4b8wX",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unlearning 500 data points for S=20, R=20...\n",
            "DataLoader size (number of batches): 157\n",
            "Iteration: 0\n",
            "Iteration: 1\n",
            "Iteration: 2\n",
            "Iteration: 3\n",
            "Iteration: 4\n",
            "Iteration: 5\n",
            "Iteration: 6\n",
            "Iteration: 7\n",
            "Iteration: 8\n",
            "Iteration: 9\n",
            "Iteration: 10\n",
            "Iteration: 11\n",
            "Iteration: 12\n",
            "Iteration: 13\n",
            "Iteration: 14\n",
            "Iteration: 15\n",
            "Iteration: 16\n",
            "Iteration: 17\n",
            "Iteration: 18\n",
            "Iteration: 19\n",
            "Iteration: 20\n",
            "Iteration: 21\n",
            "Iteration: 22\n",
            "Iteration: 23\n",
            "Iteration: 24\n",
            "Iteration: 25\n",
            "Iteration: 26\n",
            "Iteration: 27\n",
            "Iteration: 28\n",
            "Iteration: 29\n",
            "Iteration: 30\n",
            "Iteration: 31\n",
            "Iteration: 32\n",
            "Iteration: 33\n",
            "Iteration: 34\n",
            "Iteration: 35\n",
            "Iteration: 36\n",
            "Iteration: 37\n",
            "Iteration: 38\n",
            "Iteration: 39\n",
            "Iteration: 40\n",
            "Iteration: 41\n",
            "Iteration: 42\n",
            "Iteration: 43\n",
            "Iteration: 44\n",
            "Iteration: 45\n",
            "Iteration: 46\n",
            "Iteration: 47\n",
            "Iteration: 48\n",
            "Iteration: 49\n",
            "Iteration: 50\n",
            "Iteration: 51\n",
            "Iteration: 52\n",
            "Iteration: 53\n",
            "Iteration: 54\n",
            "Iteration: 55\n",
            "Iteration: 56\n",
            "Iteration: 57\n",
            "Iteration: 58\n",
            "Iteration: 59\n",
            "Iteration: 60\n",
            "Iteration: 61\n",
            "Iteration: 62\n",
            "Iteration: 63\n",
            "Iteration: 64\n",
            "Iteration: 65\n",
            "Iteration: 66\n",
            "Iteration: 67\n",
            "Iteration: 68\n",
            "Iteration: 69\n",
            "Iteration: 70\n",
            "Iteration: 71\n",
            "Iteration: 72\n",
            "Iteration: 73\n",
            "Iteration: 74\n",
            "Iteration: 75\n",
            "Iteration: 76\n",
            "Iteration: 77\n",
            "Iteration: 78\n",
            "Iteration: 79\n",
            "Iteration: 80\n",
            "Iteration: 81\n",
            "Iteration: 82\n",
            "Iteration: 83\n",
            "Iteration: 84\n",
            "Iteration: 85\n",
            "Iteration: 86\n",
            "Iteration: 87\n",
            "Iteration: 88\n",
            "Iteration: 89\n",
            "Iteration: 90\n",
            "Iteration: 91\n",
            "Iteration: 92\n",
            "Iteration: 93\n",
            "Iteration: 94\n",
            "Iteration: 95\n",
            "Iteration: 96\n",
            "Iteration: 97\n",
            "Iteration: 98\n",
            "Iteration: 99\n",
            "Iteration: 100\n",
            "Iteration: 101\n",
            "Iteration: 102\n",
            "Iteration: 103\n",
            "Iteration: 104\n",
            "Iteration: 105\n",
            "Iteration: 106\n",
            "Iteration: 107\n",
            "Iteration: 108\n",
            "Iteration: 109\n",
            "Iteration: 110\n",
            "Iteration: 111\n",
            "Iteration: 112\n",
            "Iteration: 113\n",
            "Iteration: 114\n",
            "Iteration: 115\n",
            "Iteration: 116\n",
            "Iteration: 117\n",
            "Iteration: 118\n",
            "Iteration: 119\n",
            "Iteration: 120\n",
            "Iteration: 121\n",
            "Iteration: 122\n",
            "Iteration: 123\n",
            "Iteration: 124\n",
            "Iteration: 125\n",
            "Iteration: 126\n",
            "Iteration: 127\n",
            "Iteration: 128\n",
            "Iteration: 129\n",
            "Iteration: 130\n",
            "Iteration: 131\n",
            "Iteration: 132\n",
            "Iteration: 133\n",
            "Iteration: 134\n",
            "Iteration: 135\n",
            "Iteration: 136\n",
            "Iteration: 137\n",
            "Iteration: 138\n",
            "Iteration: 139\n",
            "Iteration: 140\n",
            "Iteration: 141\n",
            "Iteration: 142\n",
            "Iteration: 143\n",
            "Iteration: 144\n",
            "Iteration: 145\n",
            "Iteration: 146\n",
            "Iteration: 147\n",
            "Iteration: 148\n",
            "Iteration: 149\n",
            "Iteration: 150\n",
            "Iteration: 151\n",
            "Iteration: 152\n",
            "Iteration: 153\n",
            "Iteration: 154\n",
            "Iteration: 155\n",
            "Iteration: 156\n",
            "The for loop in aggregate_models ran 157 times.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nUnlearning Results:\")\n",
        "\n",
        "for result in unlearning_results:\n",
        "    print(f'Configuration (S={result[\"S\"]}, R={result[\"R\"]}):')\n",
        "    print(f'F1 Score: {result[\"F1 Score\"]}')\n",
        "    print(f'Accuracy: {result[\"Accuracy\"]}')\n",
        "    print(f'Precision: {result[\"Precision\"]}')\n",
        "    print(f'Recall: {result[\"Recall\"]}')\n",
        "    print(f'AUROC: {result[\"AUROC\"]}')\n",
        "    print('----------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4KClCBPchFF",
        "outputId": "5bd26409-fd95-45e2-b37f-d1cfb9f01fe0"
      },
      "id": "U4KClCBPchFF",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unlearning Results:\n",
            "Configuration (S=20, R=20):\n",
            "F1 Score: 0.7430280426592116\n",
            "Accuracy: 0.7438\n",
            "Precision: 0.7461243187519844\n",
            "Recall: 0.7438\n",
            "AUROC: 0.9651120833333333\n",
            "----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWX-fWaJhdZ3"
      },
      "id": "DWX-fWaJhdZ3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}